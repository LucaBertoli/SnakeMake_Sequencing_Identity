# Identity Calculation Workflow
## General description
Repository developed as part of my PhD thesis.
Producing data with the lowest possible error rate is essential in NGS. However, the quality scores (Q-scores) assigned by sequencing instruments are not measurements of the actual bases sequenced. Instead, they are estimates generated by platform-specific, proprietary models (often based on optical, chemical, or signal properties of the instrument) rather than on the true error rate observed after alignment. As a result, an in-depth evaluation of each sequencing platform is required to determine whether identical Q-scores correspond to different empirical error rates.

The present repository contains an automatic and reproducible snakemake-based workflow which extracts, from an aligned BAM file, statistics regarding:
- per-read alignment identity, error counts and average sequencer-assigned Qscore
- sequencer-assigned Qscore vs empirical alignment-based Qscore
- Sequencer-assigned and empirical alignment-based Qscores stratified by sequencing cycle
- combined sequencing cycle and assigned quality stratification of empirical alignment-based Qscores and fraction of emitted bases
- insert-size stratified sequencer-assigned Qscore and empirical alignment-based Qscore

## Key Concepts
Using the pysam library, the workflow extracts mismatches from the MD tag and indels from the CIGAR string. To discriminate between true genetic variantion or alignment artifacts from sequencing errors, mismatch and indels corresponding to user-specified variants are not considered errors. Only primary-alignments are considered and reads with mapping quality less then 60 are excluded. A BED file is used as input to restrict the analysis on user-defined regions (e.g. GIAB High Confidence Regions). This is performed to mitigate the effect of misalignments on misassembled or complex regions.  

## Repository content
Main folders:
- SnakeMake_Sequencing_Identity: snakemake pipeline used to automatically produce the final report files
- scripts: collection of bash and python script used for the trimming, alignment, variant calling and graphical visualization.
- plots: legacy plots.

The snakeake workflow comprehends the following folders:

- Config
    - Run_Identity_Workflow.yml configuration yaml file, in which the key paths (input BAM, filtering VCF, filtering BED, etc.) and parameters (thread usage for multithread processing) should be specified.
- snakefile
    - Run_Identity_Workflow.smk file containing the pipeline main (rule all).
- rules
    - folder containing snakefiles, each containing independent processing rules executed by the main snakefile.
- scripts
    - folder containing the core processing python scripts, executed by the workflow's rules.

The scripts folder contains the following graphical visualization Jupyter notebooks:
- plot_identity_BQ_stratifiction.ipynb
    - python script plotting the sequencing quality stratified results 
- plot_identity_BQ_stratifiction_per_cycle.ipynb
    - python script plotting the sequencing cycle stratified results

The paths reported in these jupyter notebooks need to be modified accordingly.
## Download
The current repository should be locally cloned:

    git clone https://github.com/Lab-Delledonne-bioinfo/calcolo_identita_sequenze_Sequenziatori


## Dependencies
The workflow has the following requirements:
- snakemake
- python3
- bedtools
- samtools
  
Additionally, the following python libraries are required:
- pysam
- sys
- gzip
- math
- collections
- re
- multiprocessing
- os
- argparse
- numpy
- csv
- pandas
- matplotlib
- seaborn

## Usage

The input of the workflow comprehends:
- The BAM file generated by aligning raw reads with BWA-MEM. (adapter trimming is suggested, but no additional processing steps are required).
- The VCF containing SNV/INDEL variants. You can use a reference VCF, such as the GIAB GoldSet VCF (if analyzing a GIAB cell line), or a custom VCF called for your specific sample (e.g., from GATK). In the latter case, the VCF must be normalized using:
  
      bcftools norm $VCF -f $FASTA -m -both
- high-confidence regions BED file, in which the analyses will be performed (e.g., HG001_GRCh38_1_22_v4.2.1_benchmark.bed).
- reference genome used for the alignment
- reference genome BED file



The user should create an output directory and copy inside it the configuration and snakefile:

    mkdir results
    cd results
    cp <local repo path>/SnakeMake_Sequencing_Identity/config/Run_Identity_Workflow.yml config.yaml
    cp <local repo path>/SnakeMake_Sequencing_Identity/snakefile/Run_Identity_Workflow.smk snakefile

Then the user should modify the config.yaml according to its experimental settings, afterward the pipeline is run using:

    snakemake --cores 25

Use a multithreading option (--cores) coherent with the config.yaml file and appropriate for the infrostructure used.
